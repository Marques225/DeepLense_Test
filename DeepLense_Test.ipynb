{"cells":[{"cell_type":"code","source":["# A) Kill the current Git repo entirely\n","%cd /content\n","!rm -rf DeepLense_Test               # remove the folder\n","!rm -rf ~/.gitconfig                 # optional: clears cached user/email\n"],"metadata":{"id":"jUDLnVpBHdA2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749146523118,"user_tz":240,"elapsed":185,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}},"outputId":"ef43911f-6543-40b3-89fc-a5245bb74ed0"},"id":"jUDLnVpBHdA2","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["# In Colab – easiest via GitHub CLI, but web UI works too\n","!gh repo create Marques225/DeepLense_Test --public --confirm"],"metadata":{"id":"RH5M_FPJHdDV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749146546758,"user_tz":240,"elapsed":92,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}},"outputId":"d5a9a8de-4ec9-4645-881b-aae7b4d71a3b"},"id":"RH5M_FPJHdDV","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: gh: command not found\n"]}]},{"cell_type":"code","source":["# clone empty repo\n","!git clone https://github.com/Marques225/DeepLense_Test.git\n","%cd DeepLense_Test"],"metadata":{"id":"nwcjGLqNHdF7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749146653873,"user_tz":240,"elapsed":649,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}},"outputId":"f979dad6-cf3f-4c32-d1fa-a99b62e46353"},"id":"nwcjGLqNHdF7","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DeepLense_Test'...\n","warning: You appear to have cloned an empty repository.\n","/content/DeepLense_Test\n"]}]},{"cell_type":"code","source":["!git config --global user.name  \"Marques Wright\"\n","!git config --global user.email \"msw22500@gmail.com\""],"metadata":{"id":"bRIEryeAQ8CB","executionInfo":{"status":"ok","timestamp":1749146748904,"user_tz":240,"elapsed":236,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}}},"id":"bRIEryeAQ8CB","execution_count":7,"outputs":[]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Initial clean commit – no secrets\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbpF6sGLQ8EX","executionInfo":{"status":"ok","timestamp":1749146785186,"user_tz":240,"elapsed":237,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}},"outputId":"237964e2-d76f-46ee-a8bb-492643f04876"},"id":"AbpF6sGLQ8EX","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","\n","Initial commit\n","\n","nothing to commit (create/copy files and use \"git add\" to track)\n"]}]},{"cell_type":"code","source":["import os, getpass, subprocess\n","if \"GH_TOKEN\" not in os.environ:\n","    os.environ[\"GH_TOKEN\"] = getpass.getpass(\"GitHub PAT (hidden): \")\n","subprocess.run(\"git remote set-url origin https://$GH_TOKEN@github.com/Marques225/DeepLense_Test.git\", shell=True)\n","subprocess.run(\"git push -u origin main\", shell=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1dIBafnRlrS","executionInfo":{"status":"ok","timestamp":1749147162818,"user_tz":240,"elapsed":9359,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}},"outputId":"e05454ba-98a1-4d02-90ec-3c574e5f597a"},"id":"z1dIBafnRlrS","execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":["GitHub PAT (hidden): ··········\n"]},{"output_type":"execute_result","data":{"text/plain":["CompletedProcess(args='git push -u origin main', returncode=1)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["!find /content -maxdepth 4 -name \"DeepLense*ipynb\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4oLS7bHRovf","executionInfo":{"status":"ok","timestamp":1749147459331,"user_tz":240,"elapsed":133,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}},"outputId":"23998ba0-aa01-436c-a9a2-a1bf9026d9ba"},"id":"m4oLS7bHRovf","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/MyDrive/Colab Notebooks/DeepLense/DeepLense_Test.ipynb': No such file or directory\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wciwbAv4UPDt"},"id":"wciwbAv4UPDt","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gf6eVEW5UPGV"},"id":"gf6eVEW5UPGV","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7gFNLyM3UPIf"},"id":"7gFNLyM3UPIf","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4HBruhEsRlt8"},"id":"4HBruhEsRlt8","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LuXaLdpqQ8Lw"},"id":"LuXaLdpqQ8Lw","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"17R_aoCSHdH2"},"id":"17R_aoCSHdH2","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WKFdHQDHHdKE"},"id":"WKFdHQDHHdKE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"V0iM0cEOX1U9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749146389527,"user_tz":240,"elapsed":18366,"user":{"displayName":"Marques Wright","userId":"04231330471747283190"}},"outputId":"fe9d3a60-e4dd-4229-f275-9446c8196a96"},"id":"V0iM0cEOX1U9","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"92b4211e","metadata":{"id":"92b4211e"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Path to the folder containing the .npy files\n","data_dir = \"/content/drive/MyDrive/Colab Notebooks/Samples\"\n","\n","# List all .npy files\n","npy_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.npy')])\n","\n","# Load a sample image\n","sample_path = os.path.join(data_dir, npy_files[0])\n","sample_img = np.load(sample_path)\n","\n","print(\"Sample image shape:\", sample_img.shape)\n","\n","# Visualize\n","sample_img = sample_img.squeeze()  # shape will become (150, 150)\n","plt.imshow(sample_img, cmap='gray')\n","plt.title('Sample Lensing Image')\n","plt.axis('off')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"8e22c21f","metadata":{"id":"8e22c21f"},"outputs":[],"source":["\n","import torch\n","import numpy as np\n","import os\n","\n","# Load all images into a single tensor (may take time and memory)\n","all_images = []\n","for file in npy_files:\n","    img = np.load(os.path.join(data_dir, file))  # shape might be (1, H, W) or (H, W)\n","    all_images.append(img)\n","\n","all_images = np.array(all_images)\n","all_images = all_images.astype(np.float32) / 255.0  # Normalize\n","\n","# Convert to torch tensor\n","all_images = torch.tensor(all_images)\n","\n","# If your images have shape (N, 1, H, W) and you want (N, 1, H, W), no problem\n","# But if shape is (N, 1, 1, H, W), remove the extra 1 dim at index 2\n","if all_images.dim() == 5 and all_images.shape[2] == 1:\n","    all_images = all_images.squeeze(2)  # Remove that extra dimension\n","\n","# If images are (N, H, W), add channel dim at 1\n","elif all_images.dim() == 3:\n","    all_images = all_images.unsqueeze(1)\n","\n","print(\"Dataset shape:\", all_images.shape)"]},{"cell_type":"code","source":["'''SOLUTION ATTEMPT 2'''\n","import torch, math, numpy as np, pandas as pd\n","import torch.nn as nn, torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from skimage.metrics import peak_signal_noise_ratio as PSNR, structural_similarity as SSIM\n","\n","# ────────────────────────────── Device ──────────────────────────────────────\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# ─────────────────────── LensingDataset helper ──────────────────────────────\n","class LensingDataset(Dataset):\n","    def __init__(self, tensor):  # (N,1,H,W)\n","        self.data = tensor\n","    def __len__(self): return len(self.data)\n","    def __getitem__(self, idx):\n","        x = self.data[idx]\n","        return x  # assume already (1,H,W)\n","\n","# ───────────────────────── Time-embedding utils ─────────────────────────────\n","class SinusoidalPosEmb(nn.Module):\n","    def __init__(self, dim): super().__init__(); self.dim = dim\n","    def forward(self, t):\n","        half = self.dim // 2\n","        emb = torch.exp(torch.arange(half, device=t.device) * -(math.log(10000) / (half-1)))\n","        emb = t[:, None] * emb[None, :]\n","        return torch.cat((emb.sin(), emb.cos()), dim=-1)\n","\n","# ───────────────────────── Residual & U-Net ─────────────────────────────────\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_ch, out_ch, t_dim):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n","        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n","        self.time  = nn.Linear(t_dim, out_ch)\n","        self.act   = nn.SiLU()\n","        self.res   = nn.Conv2d(in_ch, out_ch, 1) if in_ch!=out_ch else nn.Identity()\n","    def forward(self, x, t_emb):\n","        h = self.act(self.conv1(x))\n","        h = h + self.time(t_emb)[:, :, None, None]\n","        h = self.act(self.conv2(h))\n","        return h + self.res(x)\n","\n","class BetterUNet(nn.Module):\n","    def __init__(self, img_ch=1, base=64, t_dim=256):\n","        super().__init__()\n","        self.t_emb = nn.Sequential(\n","            SinusoidalPosEmb(t_dim), nn.Linear(t_dim, t_dim*4), nn.SiLU(), nn.Linear(t_dim*4, t_dim)\n","        )\n","        self.down1 = ResidualBlock(img_ch, base, t_dim)\n","        self.down2 = ResidualBlock(base, base*2, t_dim)\n","        self.down3 = ResidualBlock(base*2, base*4, t_dim)\n","        self.pool  = nn.MaxPool2d(2)\n","        self.mid   = ResidualBlock(base*4, base*4, t_dim)\n","        self.up3   = ResidualBlock(base*8, base*2, t_dim)\n","        self.up2   = ResidualBlock(base*4, base,   t_dim)\n","        self.up1   = ResidualBlock(base*2, base,   t_dim)\n","        self.up    = nn.Upsample(scale_factor=2, mode='nearest')\n","        self.out   = nn.Conv2d(base, img_ch, 3, padding=1)\n","    def forward(self, x, t):\n","        t_emb = self.t_emb(t)\n","        h1 = self.down1(x, t_emb)\n","        h2 = self.down2(self.pool(h1), t_emb)\n","        h3 = self.down3(self.pool(h2), t_emb)\n","        h_mid = self.mid(self.pool(h3), t_emb)\n","        h = self.up(h_mid)\n","        h = F.interpolate(h, size=h3.shape[-2:], mode='nearest')\n","        h = self.up3(torch.cat([h, h3], dim=1), t_emb)\n","        h = self.up(h)\n","        h = F.interpolate(h, size=h2.shape[-2:], mode='nearest')\n","        h = self.up2(torch.cat([h, h2], dim=1), t_emb)\n","        h = self.up(h)\n","        h = F.interpolate(h, size=h1.shape[-2:], mode='nearest')\n","        h = self.up1(torch.cat([h, h1], dim=1), t_emb)\n","        return self.out(h)\n","\n","# ───────────────────────── Diffusion helpers ────────────────────────────────\n","def linear_beta_schedule(T): return torch.linspace(1e-4, 2e-2, T, device=device)\n","def get_idx(vals, t, shape): return vals.gather(0, t).view(t.size(0), *([1]*(len(shape)-1)))\n","def fwd_diff(x0, t, sqrt_ac, sqrt_1mac):\n","    noise = torch.randn_like(x0)\n","    return get_idx(sqrt_ac, t, x0.shape)*x0 + get_idx(sqrt_1mac, t, x0.shape)*noise, noise\n","\n","# ─── Multi-step DDIM Inversion (deterministic, η=0) ───────────────────────────\n","@torch.no_grad()\n","def ddim_inverse_steps(x_t, t_start, model, alpha_bar, num_steps):\n","    \"\"\"\n","    Deterministic DDIM inversion with `num_steps` from t_start -> 0.\n","    \"\"\"\n","    # build the sequence of timesteps (include t_start and 0)\n","    seq = np.linspace(t_start, 0, num_steps + 1, dtype=int)\n","    seq = np.unique(seq)[::-1]  # descending, without duplicates\n","    x = x_t\n","    for idx in range(len(seq) - 1):\n","        t = int(seq[idx])\n","        next_t = int(seq[idx + 1])\n","        # predict noise\n","        tt = torch.full((x.size(0),), t, dtype=torch.long, device=x.device)\n","        eps = model(x, tt)\n","        # compute x0 estimate\n","        sqrt_ab_t = alpha_bar[t].sqrt()\n","        sqrt_1m_ab_t = (1 - alpha_bar[t]).sqrt()\n","        x0_est = (x - sqrt_1m_ab_t * eps) / sqrt_ab_t\n","        # project to next timestep\n","        sqrt_ab_next = alpha_bar[next_t].sqrt()\n","        sqrt_1m_ab_next = (1 - alpha_bar[next_t]).sqrt()\n","        x = sqrt_ab_next * x0_est + sqrt_1m_ab_next * eps\n","    return x.clamp(0, 1)\n","\n","# ─── Compute One-step Metrics ─────────────────────────────────────────────────\n","@torch.no_grad()\n","def compute_one_step_metrics(model, x0, t, schedules):\n","    _, _, alpha_bar, sqrt_ab, sqrt_1m_ab = schedules\n","    noise = torch.randn_like(x0)\n","    x_t = sqrt_ab[t] * x0 + sqrt_1m_ab[t] * noise\n","    eps_pred = model(x_t, torch.full((x0.size(0),), t, dtype=torch.long, device=device))\n","    mse = F.mse_loss(eps_pred, noise).item()\n","    corr = ((eps_pred.flatten() * noise.flatten()).mean() /\n","            (eps_pred.std() * noise.std())).item()\n","    x0_hat = (x_t - sqrt_1m_ab[t] * eps_pred) / sqrt_ab[t]\n","    x0_np, x0_hat_np = x0.cpu().numpy(), x0_hat.cpu().numpy()\n","    psnrs = [PSNR(a.squeeze(), b.squeeze(), data_range=1.0) for a, b in zip(x0_np, x0_hat_np)]\n","    ssims = [SSIM(a.squeeze(), b.squeeze(), data_range=1.0) for a, b in zip(x0_np, x0_hat_np)]\n","    return {'noise_mse': mse, 'noise_corr': corr,\n","            'psnr_1step': np.mean(psnrs), 'ssim_1step': np.mean(ssims)}\n","\n","# ─── Training with Integrated Metrics ─────────────────────────────────────────\n","def train(model, train_loader, val_loader, opt, T,\n","          epochs=100, ema_decay=0.999, val_interval=5):\n","    # prepare schedules and EMA\n","    beta = linear_beta_schedule(T)\n","    alpha = 1 - beta\n","    alpha_bar = torch.cumprod(alpha, 0)\n","    sqrt_ab, sqrt_1m_ab = alpha_bar.sqrt(), (1 - alpha_bar).sqrt()\n","    schedules = (beta, alpha, alpha_bar, sqrt_ab, sqrt_1m_ab)\n","    ema = BetterUNet().to(device)\n","    ema.load_state_dict(model.state_dict())\n","    for p in ema.parameters(): p.requires_grad_(False)\n","\n","    metrics = []\n","    best_loss = float('inf')\n","    no_improve = 0\n","    for ep in range(1, epochs + 1):\n","        # TRAIN STEP\n","        model.train()\n","        ep_loss = 0.0\n","        for x in tqdm(train_loader, desc=f\"Epoch {ep}\"):\n","            x = x.to(device)\n","            t = torch.randint(0, T, (x.size(0),), device=device).long()\n","            x_t, noise = fwd_diff(x, t, sqrt_ab, sqrt_1m_ab)\n","            pred = model(x_t, t)\n","            loss = F.mse_loss(pred, noise)\n","            opt.zero_grad(); loss.backward(); opt.step()\n","            ep_loss += loss.item()\n","            # EMA update\n","            with torch.no_grad():\n","                for pe, p in zip(ema.parameters(), model.parameters()):\n","                    pe.data.mul_(ema_decay).add_(p.data, alpha=1-ema_decay)\n","        ep_loss /= len(train_loader)\n","        # checkpoint EMA\n","        if ep_loss < best_loss:\n","            best_loss = ep_loss; no_improve = 0\n","            torch.save(ema.state_dict(), 'best_ema.pt')\n","        else:\n","            no_improve += 1\n","        if no_improve > 10: break\n","\n","        # VALIDATION METRICS\n","        if ep % val_interval == 0:\n","            for split, loader in [('train', train_loader), ('val', val_loader)]:\n","                x0 = next(iter(loader)).to(device)\n","                for t in [50, 200, 400, 800]:\n","                    # one-step\n","                    one = compute_one_step_metrics(ema, x0, t, schedules)\n","                    one.update({'epoch': ep, 'split': split, 't': t, 'steps': 1})\n","                    metrics.append(one)\n","                    # multi-step\n","                    for steps in [5, 10, 25, 50]:\n","                        x_t = sqrt_ab[t] * x0 + sqrt_1m_ab[t] * torch.randn_like(x0)\n","                        x_rec = ddim_inverse_steps(x_t, t, ema, alpha_bar, steps)\n","                        x_np, rec_np = x0.cpu().numpy(), x_rec.cpu().numpy()\n","                        psnrs = [PSNR(a.squeeze(), b.squeeze(), data_range=1.0)\n","                                 for a, b in zip(x_np, rec_np)]\n","                        ssims = [SSIM(a.squeeze(), b.squeeze(), data_range=1.0)\n","                                 for a, b in zip(x_np, rec_np)]\n","                        row = {'epoch': ep, 'split': split, 't': t,\n","                               'steps': steps,\n","                               'psnr_steps': np.mean(psnrs),\n","                               'ssim_steps': np.mean(ssims)}\n","                        metrics.append(row)\n","\n","    # finish up\n","    df = pd.DataFrame(metrics)\n","    df.to_csv('metrics_log_two.csv', index=False)\n","    return ema, df\n","\n","# ─── Main Entrypoint ─────────────────────────────────────────────────────────\n","if __name__ == '__main__':\n","\n","    train_ds, val_ds = torch.utils.data.random_split(\n","        all_images, [int(0.9*len(all_images)), len(all_images) - int(0.9*len(all_images))]\n","    )\n","    train_loader = DataLoader(LensingDataset(train_ds), batch_size=64, shuffle=True)\n","    val_loader   = DataLoader(LensingDataset(val_ds),   batch_size=64, shuffle=False)\n","\n","    model = BetterUNet().to(device)\n","    opt   = torch.optim.AdamW(model.parameters(), lr=3e-4)\n","    ema_model, metrics_df = train(model, train_loader, val_loader, opt,\n","                                  T=1000, epochs=100, val_interval=5)\n","\n","    print(metrics_df.head())"],"metadata":{"id":"WAaFOuc3bqUK"},"id":"WAaFOuc3bqUK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''SOLUTION ATTEMPT 2'''\n","checkpoint = 'best_ema.pt'       # path to your EMA checkpoint\n","num_steps  = 25\n","timesteps  = [50, 200, 400, 800]\n","n_samples  = 4   # how many val images to visualize\n","\n","# ─── Helpers ─────────────────────────────────────────────────────────────────\n","def linear_beta_schedule(T):\n","    return torch.linspace(1e-4, 2e-2, T, device=device)\n","\n","def ddim_inverse_steps(x_t, t_start, model, alpha_bar, steps):\n","    seq = np.linspace(t_start, 0, steps+1, dtype=int)\n","    seq = np.unique(seq)[::-1]\n","    x = x_t\n","    for i in range(len(seq)-1):\n","        t, nt = int(seq[i]), int(seq[i+1])\n","        tt = torch.full((x.size(0),), t, dtype=torch.long, device=device)\n","        eps = model(x, tt)\n","        sqrt_ab  = alpha_bar[t].sqrt()\n","        sqrt_1ma = (1-alpha_bar[t]).sqrt()\n","        x0_est   = (x - sqrt_1ma*eps)/sqrt_ab\n","        sqrt_ab2  = alpha_bar[nt].sqrt()\n","        sqrt_1ma2 = (1-alpha_bar[nt]).sqrt()\n","        x = sqrt_ab2*x0_est + sqrt_1ma2*eps\n","    return x.clamp(0,1)\n","\n","# ─── Load model & schedule ────────────────────────────────────────────────────\n","model = BetterUNet().to(device)\n","ckpt  = torch.load(checkpoint, map_location=device)\n","model.load_state_dict(ckpt)\n","model.eval()\n","\n","T = 1000\n","beta = linear_beta_schedule(T)\n","alpha = 1 - beta\n","alpha_bar = torch.cumprod(alpha, 0)\n","\n","# ─── Visualization ───────────────────────────────────────────────────────────\n","val_ds = all_images[int(0.9*len(all_images)):]\n","model.eval()\n","with torch.no_grad():\n","    samples = val_ds[:n_samples].to(device)\n","\n","    fig, axes = plt.subplots(n_samples, len(timesteps)*4,\n","                             figsize=(4*len(timesteps), 3*n_samples))\n","\n","    for i, x0 in enumerate(samples):\n","        x0 = x0.unsqueeze(0)\n","\n","        for j, t in enumerate(timesteps):\n","            # forward noise\n","            noise    = torch.randn_like(x0)\n","            sqrt_ab  = alpha_bar[t].sqrt()\n","            sqrt_1ma = (1 - alpha_bar[t]).sqrt()\n","            x_t      = sqrt_ab * x0 + sqrt_1ma * noise\n","\n","            # 1-step\n","            tt = torch.full((1,), t, dtype=torch.long, device=device)\n","            eps = model(x_t, tt)\n","            x1  = (x_t - sqrt_1ma * eps) / sqrt_ab\n","\n","            # 25-step\n","            x25 = ddim_inverse_steps(x_t, t, model, alpha_bar, num_steps)\n","\n","            # compute metrics (detach so no grad)\n","            a0 = x0.detach().cpu().numpy().squeeze()\n","            a1 = x1.detach().cpu().numpy().squeeze()\n","            a25 = x25.detach().cpu().numpy().squeeze()\n","\n","            p1 = PSNR(a0,  a1,  data_range=1.0)\n","            s1 = SSIM(a0,  a1,  data_range=1.0)\n","            p2 = PSNR(a0, a25, data_range=1.0)\n","            s2 = SSIM(a0, a25, data_range=1.0)\n","\n","            imgs   = [x0, x_t, x1, x25]\n","            titles = [\n","                \"Real\",\n","                f\"Noised t={t}\",\n","                f\"1-step\\nPSNR {p1:.1f}dB\\nSSIM {s1:.3f}\",\n","                f\"25-step\\nPSNR {p2:.1f}dB\\nSSIM {s2:.3f}\"\n","            ]\n","\n","            for k, (im, title) in enumerate(zip(imgs, titles)):\n","                arr = im.detach().cpu().squeeze()        # ② detach here too\n","                ax  = axes[i, j*4 + k]\n","                ax.imshow(arr, cmap='gray')\n","                ax.set_title(title, fontsize=8)\n","                ax.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n"],"metadata":{"id":"BfD1hr1LDD6i"},"id":"BfD1hr1LDD6i","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install diffusers accelerate"],"metadata":{"id":"mlrwFvWviAn_"},"id":"mlrwFvWviAn_","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"w4moGmSrMPQo"},"id":"w4moGmSrMPQo"},{"cell_type":"code","source":["'''SOLUTION ATTEMPT 1'''\n","\n","import torch, math, numpy as np\n","import torch.nn as nn, torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","\n","# ────────────────────────────── Device ──────────────────────────────────────\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","\n","# ─────────────────────── LensingDataset helper ──────────────────────────────\n","class LensingDataset(Dataset):\n","    def __init__(self, tensor):                       # (N, 1, 150, 150)\n","        self.data = tensor\n","    def __len__(self):  return len(self.data)\n","    def __getitem__(self, idx):\n","        x = self.data[idx]\n","        if x.dim() == 4 and x.shape[1] == 1:          # squeeze stray dim\n","            x = x.squeeze(1)\n","        return x\n","\n","# ───────────────────────── Time-embedding utils ─────────────────────────────\n","class SinusoidalPosEmb(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__(); self.dim=dim\n","    def forward(self, t):                             # t: (B,)\n","        half = self.dim // 2\n","        emb  = torch.exp(torch.arange(half, device=t.device) *\n","                         -(math.log(10000) / (half-1)))\n","        emb  = t[:,None] * emb[None,:]\n","        return torch.cat((emb.sin(), emb.cos()), dim=-1)   # (B,dim)\n","\n","# ───────────────────────── Residual block ───────────────────────────────────\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_ch, out_ch, t_dim):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n","        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1)\n","        self.time  = nn.Linear(t_dim, out_ch)\n","        self.act   = nn.SiLU()\n","        self.res   = nn.Conv2d(in_ch, out_ch, 1) if in_ch!=out_ch else nn.Identity()\n","    def forward(self, x, t_emb):\n","        h = self.act(self.conv1(x))\n","        h = h + self.time(t_emb)[:, :, None, None]\n","        h = self.act(self.conv2(h))\n","        return h + self.res(x)\n","\n","# ───────────────────────── Better U-Net (≈ 7 M) ─────────────────────────────\n","class BetterUNet(nn.Module):\n","    def __init__(self, img_ch=1, base=64, t_dim=256):\n","        super().__init__()\n","        # time embedding MLP\n","        self.t_emb = nn.Sequential(\n","            SinusoidalPosEmb(t_dim), nn.Linear(t_dim, t_dim*4), nn.SiLU(),\n","            nn.Linear(t_dim*4, t_dim)\n","        )\n","        # encoder\n","        self.down1 = ResidualBlock(img_ch,       base,   t_dim)\n","        self.down2 = ResidualBlock(base,         base*2, t_dim)\n","        self.down3 = ResidualBlock(base*2,       base*4, t_dim)\n","        self.pool  = nn.MaxPool2d(2)\n","        # bottleneck\n","        self.mid   = ResidualBlock(base*4,       base*4, t_dim)\n","        # decoder\n","        self.up3   = ResidualBlock(base*8,       base*2, t_dim)\n","        self.up2   = ResidualBlock(base*4,       base,   t_dim)\n","        self.up1   = ResidualBlock(base*2,       base,   t_dim)\n","        self.up    = nn.Upsample(scale_factor=2, mode='nearest')\n","        self.out   = nn.Conv2d(base, img_ch, 3, 1, 1)\n","\n","    def forward(self, x, t):\n","      t_emb = self.t_emb(t)\n","\n","      # encoder\n","      h1 = self.down1(x,                 t_emb)           # 150\n","      h2 = self.down2(self.pool(h1),     t_emb)           # 75\n","      h3 = self.down3(self.pool(h2),     t_emb)           # 37\n","      h_mid = self.mid(self.pool(h3),    t_emb)           # 18\n","\n","      # decoder  (resize to exactly match the skip tensor)\n","      h = self.up(h_mid)\n","      h = F.interpolate(h, size=h3.shape[-2:], mode=\"nearest\")\n","      h = self.up3(torch.cat([h, h3], 1), t_emb)\n","\n","      h = self.up(h)\n","      h = F.interpolate(h, size=h2.shape[-2:], mode=\"nearest\")\n","      h = self.up2(torch.cat([h, h2], 1), t_emb)\n","\n","      h = self.up(h)\n","      h = F.interpolate(h, size=h1.shape[-2:], mode=\"nearest\")\n","      h = self.up1(torch.cat([h, h1], 1), t_emb)\n","\n","      return self.out(h)\n","\n","# ───────────────────────── Diffusion helpers ────────────────────────────────\n","def linear_beta_schedule(T):  return torch.linspace(1e-4, 2e-2, T, device=device)\n","\n","def get_idx(vals, t, shp):\n","    out = vals.gather(-1, t).view(t.size(0), *((1,)*(len(shp)-1)))\n","    return out\n","def fwd_diff(x0, t, sqrt_ac, sqrt_1mac):\n","    noise = torch.randn_like(x0)\n","    return get_idx(sqrt_ac,t,x0.shape)*x0 + get_idx(sqrt_1mac,t,x0.shape)*noise, noise\n","\n","# ───────────────────────── Training loop  + EMA  ────────────────────────────\n","def train(model, loader, opt, T, epochs=100, ema_decay=0.999,\n","          patience=10, min_delta=1e-5):\n","    beta  = linear_beta_schedule(T)\n","    alpha = 1. - beta\n","    ac    = torch.cumprod(alpha, 0)\n","    sqrt_ac, sqrt_1mac = ac.sqrt(), (1 - ac).sqrt()\n","\n","    mse   = nn.MSELoss()\n","\n","    # ─── EMA shadow net ─────────────────────────────────────────────\n","    ema = BetterUNet().to(device)\n","    ema.load_state_dict(model.state_dict())\n","    for p in ema.parameters(): p.requires_grad_(False)\n","\n","    best_loss = float('inf')\n","    epochs_no_improve = 0         # early-stop counter\n","\n","    for ep in range(1, epochs + 1):\n","        pbar = tqdm(enumerate(loader), total=len(loader),\n","                    desc=f\"Epoch {ep}\")\n","        epoch_loss = 0.0\n","\n","        for batch_idx, x in pbar:\n","            x = x.to(device)\n","            t = torch.randint(0, T, (x.size(0),), device=device).long()\n","            x_t, noise = fwd_diff(x, t, sqrt_ac, sqrt_1mac)\n","\n","            # one-time debug on very first batch\n","            if ep == 1 and batch_idx == 0:\n","                with torch.no_grad():\n","                    mae_dbg = (model(x_t, t) - noise).abs().mean()\n","                    print(\"MAE(noise,pred) first batch:\", mae_dbg.item())\n","\n","            pred  = model(x_t, t)\n","            loss  = mse(pred, noise)\n","            epoch_loss += loss.item()\n","\n","            opt.zero_grad(); loss.backward(); opt.step()\n","\n","            # EMA update\n","            with torch.no_grad():\n","                for pe, p in zip(ema.parameters(), model.parameters()):\n","                    pe.data.mul_(ema_decay).add_(p.data, alpha=1-ema_decay)\n","\n","            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n","\n","        epoch_loss /= len(loader)          # mean loss this epoch\n","\n","        # ─── early-stopping & checkpoint ───────────────────────────\n","        if epoch_loss < best_loss - min_delta:\n","            best_loss = epoch_loss\n","            epochs_no_improve = 0\n","            torch.save(ema.state_dict(), \"best_ema.pt\")\n","            print(f\"✓ saved best EMA (loss {best_loss:.4e})\")\n","        else:\n","            epochs_no_improve += 1\n","            if epochs_no_improve >= patience:\n","                print(f\"Early-stopping: no improvement for {patience} epochs.\")\n","                break\n","# ───────────────────────── Load your tensor 'all_images' ────────────────────\n","# all_images = torch.tensor(..., dtype=torch.float32)/255.\n","# shape must be (N,1,150,150)\n","print('Original dataset shape:', all_images.shape)\n","\n","train_sz = int(0.9*len(all_images))\n","val_sz   = len(all_images)-train_sz\n","train_ds,_ = torch.utils.data.random_split(all_images, [train_sz, val_sz])\n","train_loader = DataLoader(LensingDataset(train_ds), batch_size=64, shuffle=True)\n","\n","model = BetterUNet().to(device)\n","opt   = torch.optim.AdamW(model.parameters(), lr=3e-4)\n","train(model, train_loader, opt, T=1000, epochs=100)\n"],"metadata":{"id":"welR2t_stGiV"},"id":"welR2t_stGiV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''SOLUTION ATTEMPT 1'''\n","\n","# grab the first convolution weight tensor\n","w_loaded = model.down1.conv1.weight.view(-1)[:5].cpu()\n","print(\"first 5 weights from checkpoint:\", w_loaded)\n","\n","# rebuild a *fresh* model (random weights) and print the same tensor\n","fresh = BetterUNet().to(device)\n","w_rand  = fresh.down1.conv1.weight.view(-1)[:5].cpu()\n","print(\"first 5 random weights        :\", w_rand)\n"],"metadata":{"id":"rHnLTq1rNHqL"},"id":"rHnLTq1rNHqL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''SOLUTION ATTEMPT 1'''\n","\n","import torch\n","import matplotlib.pyplot as plt\n","\n","# ─── 1) Load model ───────────────────────────────────────────────────────────────\n","def load_model(path, device):\n","    model = BetterUNet().to(device)\n","    ckpt = torch.load(path, map_location=device)\n","    model.load_state_dict(ckpt)\n","    model.eval()  # use running stats, disable dropout\n","    return model\n","\n","# ─── 2) Build β/α schedules (must match your training) ───────────────────────────\n","def make_schedules(T, device):\n","    beta      = torch.linspace(1e-4, 2e-2, T, device=device)\n","    alpha     = 1.0 - beta\n","    alpha_bar = torch.cumprod(alpha, dim=0)\n","    sqrt_ab   = alpha_bar.sqrt()\n","    sqrt_1m_ab= (1.0 - alpha_bar).sqrt()\n","    return beta, alpha, alpha_bar, sqrt_ab, sqrt_1m_ab\n","\n","# ─── 3) One‐step closed‐form inversion (quick sanity check) ─────────────────────\n","@torch.no_grad()\n","def one_step_inversion(x_t, t, model, sqrt_ab, sqrt_1m_ab):\n","    eps_pred = model(x_t, torch.full((x_t.size(0),), t,\n","                                     dtype=torch.long, device=x_t.device))\n","    x0_hat   = (x_t - sqrt_1m_ab[t] * eps_pred) / sqrt_ab[t]\n","    return x0_hat.clamp(0.0,1.0), eps_pred\n","\n","# ─── 4) Deterministic DDIM inversion (η=0) ───────────────────────────────────────\n","@torch.no_grad()\n","def reconstruct_ddim(x_t, t_start, model, alpha_bar):\n","    x = x_t\n","    for t in range(t_start, 0, -1):  # t_start → 1\n","        tt          = torch.full((x.size(0),), t,\n","                                  dtype=torch.long, device=x.device)\n","        eps         = model(x, tt)\n","        sqrt_ab_t   = alpha_bar[t].sqrt()\n","        sqrt_1m_ab_t= (1.0 - alpha_bar[t]).sqrt()\n","        # one-shot x0 estimate\n","        x0_est      = (x - sqrt_1m_ab_t * eps) / sqrt_ab_t\n","        # project to x_{t-1}\n","        sqrt_ab_t1   = alpha_bar[t-1].sqrt()\n","        sqrt_1m_ab_t1= (1.0 - alpha_bar[t-1]).sqrt()\n","        x = sqrt_ab_t1 * x0_est + sqrt_1m_ab_t1 * eps\n","    return x.clamp(0.0,1.0)\n","\n","# ─── 5) Diagnostics & Visualization ─────────────────────────────────────────────\n","if __name__ == \"__main__\":\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model, T = load_model('best_ema.pt', device), 1000\n","    beta, alpha, alpha_bar, sqrt_ab, sqrt_1m_ab = make_schedules(T, device)\n","\n","    # timesteps to test (skip t=0 for inversion)\n","    timesteps = [50, 200, 400, 800]\n","    x0 = all_images[0:1].to(device)  # shape (1,1,H,W), float32 ∈ [0,1]\n","\n","    fig, axes = plt.subplots(len(timesteps), 4, figsize=(12, 3*len(timesteps)))\n","    for i, t in enumerate(timesteps):\n","        # forward noise\n","        noise = torch.randn_like(x0)\n","        x_t   = sqrt_ab[t] * x0 + sqrt_1m_ab[t] * noise\n","\n","        print(f\"t={t}: x_t range [{x_t.min():.3f}, {x_t.max():.3f}]\")\n","\n","        # 1-step inversion & noise metrics\n","        x0_hat, eps_pred = one_step_inversion(x_t, t, model, sqrt_ab, sqrt_1m_ab)\n","        mse  = torch.mean((eps_pred - noise)**2).item()\n","        corr = ((eps_pred.flatten()*noise.flatten()).mean() /\n","                (eps_pred.std()*noise.std())).item()\n","        print(f\"  noise-MSE={mse:.4e}, corr={corr:.3f}\")\n","\n","        # deterministic full inversion\n","        x_rec = reconstruct_ddim(x_t, t, model, alpha_bar)\n","\n","        # plot real, noised, 1-step, DDIM-recon\n","        for j, (img, title) in enumerate(zip(\n","                [x0, x_t, x0_hat, x_rec],\n","                ['real','noised','1-step','DDIM-recon'])):\n","            ax = axes[i, j]\n","            ax.imshow(img[0,0].cpu(), cmap='gray')\n","            ax.set_title(title)\n","            ax.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"-xEZVEf4FgT2"},"id":"-xEZVEf4FgT2","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"35a1f564","metadata":{"id":"35a1f564"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"24cd9ad8","metadata":{"id":"24cd9ad8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"15826f5f","metadata":{"id":"15826f5f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9d9c94ff","metadata":{"id":"9d9c94ff"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0509dc27","metadata":{"id":"0509dc27"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e4bc245c","metadata":{"id":"e4bc245c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"cf81b5b9","metadata":{"id":"cf81b5b9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9eba2052","metadata":{"id":"9eba2052"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"62600d01","metadata":{"id":"62600d01"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ee57c947","metadata":{"id":"ee57c947"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"059537fe","metadata":{"id":"059537fe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"86dd40dc","metadata":{"id":"86dd40dc"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"366f1dd2","metadata":{"id":"366f1dd2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"854eb96b","metadata":{"id":"854eb96b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"8e77e851","metadata":{"id":"8e77e851"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":5}